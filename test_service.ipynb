{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "[{'detection_classes': [], 'detection_boxes': [], 'detection_scores': []}, {'detection_classes': ['yellow_back'], 'detection_boxes': [[1193.163330078125, 659.060302734375, 1277.5, 718.8507690429688]], 'detection_scores': [0.5130099654197693]}]\n"
     ]
    }
   ],
   "source": [
    "# %load customize_service.py\n",
    "# from model_service.pytorch_model_service import PTServingBaseService\n",
    "from backbone import EfficientDetBackbone\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine\n",
    "import torch\n",
    "import numpy as np\n",
    "from tools import cfg\n",
    "import yaml\n",
    "from torchvision.ops import nms\n",
    "from torchvision.ops.boxes import batched_nms\n",
    "\n",
    "\n",
    "class PTVisionService:\n",
    "\n",
    "    def __init__(self, model_name, model_path):\n",
    "        # 调用父类构造方法\n",
    "        # super(PTVisionService, self).__init__(model_name, model_path)\n",
    "        # 调用自定义函数加载模型\n",
    "        checkpoint_file = model_path\n",
    "        params = yaml.safe_load(open(f'projects/{cfg.project}.yml'))\n",
    "        self.model = EfficientDetBackbone(compound_coef=cfg.compound_coef, num_classes=len(cfg.category),\n",
    "                                     ratios=eval(params['anchors_ratios']), scales=eval(params['anchors_scales']))\n",
    "        self.model.load_state_dict(torch.load(checkpoint_file, map_location=torch.device('cpu')))\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.eval()\n",
    "        self.input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "        self.class_dict = dict([val, key] for key, val in cfg.category.items())\n",
    "        \n",
    "    def mypreprocess(self, data):\n",
    "        # https两种请求形式\n",
    "        # 1. form-data文件格式的请求对应：data = {\"请求key值\":{\"文件名\":<文件io>}}\n",
    "        # 2. json格式对应：data = json.loads(\"接口传入的json体\")\n",
    "        imgs_path = []\n",
    "        for k, v in data.items():\n",
    "            for file_name, file_content in v.items():\n",
    "                imgs_path.append(file_content)\n",
    "        \n",
    "        return imgs_path\n",
    "    \n",
    "    def myinference(self, imgs_path):\n",
    "        results = []\n",
    "        regressBoxes = BBoxTransform()\n",
    "        clipBoxes = ClipBoxes()\n",
    "        for img_path in imgs_path:\n",
    "            ori_imgs, framed_imgs, framed_metas = preprocess([img_path], max_size=self.input_sizes[cfg.compound_coef])\n",
    "            x = torch.from_numpy(framed_imgs[0]).float()\n",
    "            x = x.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "            print(x.shape)\n",
    "\n",
    "            features, regression, classification, anchors = self.model(x)\n",
    "            preds = self._my_postprocess(x,\n",
    "                                anchors, regression, classification,\n",
    "                                regressBoxes, clipBoxes,\n",
    "                                cfg.threshold, cfg.nms_threshold)\n",
    "\n",
    "            preds = invert_affine(framed_metas, preds)[0]\n",
    "            scores = preds['scores']\n",
    "            class_ids = preds['class_ids']\n",
    "            rois = preds['rois']\n",
    "            image_result = {\n",
    "                'detection_classes': [],\n",
    "                'detection_boxes': [],\n",
    "                'detection_scores': []\n",
    "            }\n",
    "            if rois.shape[0] > 0:\n",
    "                bbox_score = scores\n",
    "                \n",
    "                for roi_id in range(rois.shape[0]):\n",
    "                    score = float(bbox_score[roi_id])\n",
    "                    label = int(class_ids[roi_id])\n",
    "                    box = rois[roi_id, :]\n",
    "                    image_result['detection_classes'].append(self.class_dict[label+1])\n",
    "                    image_result['detection_boxes'].append(box.tolist())\n",
    "                    image_result['detection_scores'].append(score)\n",
    "\n",
    "            results.append(image_result)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def mypostprocess(self, data):\n",
    "        if len(data) == 1:\n",
    "            return data[0]\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    def _my_postprocess(self, x, anchors, regression, classification, regressBoxes, clipBoxes, threshold, iou_threshold):\n",
    "        transformed_anchors = regressBoxes(anchors, regression)\n",
    "        transformed_anchors = clipBoxes(transformed_anchors, x)\n",
    "        scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
    "        scores_over_thresh = (scores > threshold)[:, :, 0]\n",
    "        out = []\n",
    "        for i in range(x.shape[0]):\n",
    "            if scores_over_thresh[i].sum() == 0:\n",
    "                out.append({\n",
    "                    'rois': np.array(()),\n",
    "                    'class_ids': np.array(()),\n",
    "                    'scores': np.array(()),\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            classification_per = classification[i, scores_over_thresh[i, :], ...].permute(1, 0)\n",
    "            transformed_anchors_per = transformed_anchors[i, scores_over_thresh[i, :], ...]\n",
    "            scores_per = scores[i, scores_over_thresh[i, :], ...]\n",
    "            scores_, classes_ = classification_per.max(dim=0)\n",
    "            anchors_nms_idx = batched_nms(transformed_anchors_per, scores_per[:, 0], classes_, iou_threshold=iou_threshold)\n",
    "\n",
    "            if anchors_nms_idx.shape[0] != 0:\n",
    "                classes_ = classes_[anchors_nms_idx]\n",
    "                scores_ = scores_[anchors_nms_idx]\n",
    "                boxes_ = transformed_anchors_per[anchors_nms_idx, :]\n",
    "\n",
    "                out.append({\n",
    "                    'rois': boxes_.numpy(),\n",
    "                    'class_ids': classes_.numpy(),\n",
    "                    'scores': scores_.numpy(),\n",
    "                })\n",
    "            else:\n",
    "                out.append({\n",
    "                    'rois': np.array(()),\n",
    "                    'class_ids': np.array(()),\n",
    "                    'scores': np.array(()),\n",
    "                })\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "service = PTVisionService(1, 'logs/auto/efficientdet-d0_1_500.pth')\n",
    "data = service.mypreprocess({'key':{'file1': 'data/labeled_data_backup/1.jpg',\n",
    "                                  'file2': 'data/labeled_data_backup/3.jpg'}})\n",
    "\n",
    "data = service.myinference(data)\n",
    "data = service.mypostprocess(data)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 31,  36,  34],\n",
      "        [ 32,  37,  35],\n",
      "        [ 35,  38,  36],\n",
      "        ...,\n",
      "        [112, 113, 111],\n",
      "        [115, 116, 114],\n",
      "        [114, 115, 113]],\n",
      "\n",
      "       [[ 26,  31,  29],\n",
      "        [ 33,  38,  36],\n",
      "        [ 32,  35,  33],\n",
      "        ...,\n",
      "        [115, 116, 114],\n",
      "        [116, 117, 115],\n",
      "        [114, 115, 113]],\n",
      "\n",
      "       [[ 30,  35,  33],\n",
      "        [ 37,  42,  40],\n",
      "        [ 30,  33,  31],\n",
      "        ...,\n",
      "        [113, 114, 112],\n",
      "        [114, 115, 113],\n",
      "        [115, 116, 114]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 54,  51,  43],\n",
      "        [ 55,  52,  44],\n",
      "        [ 62,  59,  51],\n",
      "        ...,\n",
      "        [  1,   4,   2],\n",
      "        [  2,   5,   3],\n",
      "        [  3,   6,   4]],\n",
      "\n",
      "       [[ 53,  47,  40],\n",
      "        [ 52,  46,  39],\n",
      "        [ 56,  50,  43],\n",
      "        ...,\n",
      "        [  1,   4,   2],\n",
      "        [  2,   5,   3],\n",
      "        [  5,   8,   6]],\n",
      "\n",
      "       [[ 52,  46,  39],\n",
      "        [ 50,  44,  37],\n",
      "        [ 51,  45,  38],\n",
      "        ...,\n",
      "        [  0,   3,   1],\n",
      "        [  1,   4,   2],\n",
      "        [  4,   7,   5]]], dtype=uint8), array([[[ 94,  75,  48],\n",
      "        [143, 126,  99],\n",
      "        [157, 140, 113],\n",
      "        ...,\n",
      "        [180, 184, 173],\n",
      "        [179, 183, 172],\n",
      "        [178, 182, 171]],\n",
      "\n",
      "       [[ 74,  55,  28],\n",
      "        [104,  85,  58],\n",
      "        [152, 135, 108],\n",
      "        ...,\n",
      "        [180, 184, 173],\n",
      "        [179, 183, 172],\n",
      "        [179, 183, 172]],\n",
      "\n",
      "       [[ 67,  46,  19],\n",
      "        [ 75,  56,  29],\n",
      "        [123, 106,  79],\n",
      "        ...,\n",
      "        [179, 183, 172],\n",
      "        [179, 182, 173],\n",
      "        [179, 182, 173]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 70,  48,  37],\n",
      "        [ 75,  53,  42],\n",
      "        [ 82,  60,  49],\n",
      "        ...,\n",
      "        [ 18,  19,  15],\n",
      "        [ 19,  20,  16],\n",
      "        [ 20,  21,  17]],\n",
      "\n",
      "       [[ 72,  47,  37],\n",
      "        [ 75,  50,  40],\n",
      "        [ 75,  50,  40],\n",
      "        ...,\n",
      "        [ 18,  19,  15],\n",
      "        [ 18,  19,  15],\n",
      "        [ 18,  19,  15]],\n",
      "\n",
      "       [[ 68,  43,  33],\n",
      "        [ 72,  47,  37],\n",
      "        [ 70,  45,  35],\n",
      "        ...,\n",
      "        [ 17,  18,  14],\n",
      "        [ 16,  17,  13],\n",
      "        [ 17,  18,  14]]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "pic_list = ['data/labeled_data_backup/1.jpg', 'data/labeled_data_backup/3.jpg']\n",
    "pic = [cv2.imread(item) for item in pic_list]\n",
    "print(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python lmw-pt",
   "language": "python",
   "name": "lmw-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
