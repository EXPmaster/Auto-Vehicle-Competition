{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detection_classes': ['speed_limited', 'speed_unlimited'], 'detection_boxes': [[428.83355712890625, 702.7015380859375, 492.35333251953125, 754.12109375], [426.2160339355469, 384.92425537109375, 486.7881774902344, 425.0550537109375]], 'detection_scores': [0.9783390760421753, 0.9107725024223328]}\n"
     ]
    }
   ],
   "source": [
    "# %load customize_service.py\n",
    "# import os\n",
    "# import sys\n",
    "# current_path = os.path.dirname(__file__)\n",
    "# sys.path.append(current_path)\n",
    "# from model_service.pytorch_model_service import PTServingBaseService\n",
    "from backbone import EfficientDetBackbone\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from uts.utils import preprocess, invert_affine\n",
    "import torch\n",
    "import numpy as np\n",
    "from tools import cfg\n",
    "import yaml\n",
    "from torchvision.ops import nms\n",
    "from torchvision.ops.boxes import batched_nms\n",
    "\n",
    "\n",
    "class PTVisionService:\n",
    "\n",
    "    def __init__(self, model_name, model_path):\n",
    "        # 调用父类构造方法\n",
    "        # super(PTVisionService, self).__init__(model_name, model_path)\n",
    "        # 调用自定义函数加载模型\n",
    "        checkpoint_file = model_path\n",
    "        params = yaml.safe_load(open(f'projects/{cfg.project}.yml'))\n",
    "        self.model = EfficientDetBackbone(compound_coef=cfg.compound_coef, num_classes=len(cfg.category),\n",
    "                                     ratios=eval(params['anchors_ratios']), scales=eval(params['anchors_scales']))\n",
    "        self.model.load_state_dict(torch.load(checkpoint_file, map_location=torch.device('cpu')))\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.eval()\n",
    "        self.input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "        self.class_dict = dict([val, key] for key, val in cfg.category.items())\n",
    "        \n",
    "    def preprocess(self, data):\n",
    "        # https两种请求形式\n",
    "        # 1. form-data文件格式的请求对应：data = {\"请求key值\":{\"文件名\":<文件io>}}\n",
    "        # 2. json格式对应：data = json.loads(\"接口传入的json体\")\n",
    "        imgs_path = []\n",
    "        for k, v in data.items():\n",
    "            for file_name, file_content in v.items():\n",
    "                imgs_path.append(file_content)\n",
    "\n",
    "        return imgs_path\n",
    "    \n",
    "    def inference(self, imgs_path):\n",
    "        results = []\n",
    "        regressBoxes = BBoxTransform()\n",
    "        clipBoxes = ClipBoxes()\n",
    "        for img_path in imgs_path:\n",
    "            ori_imgs, framed_imgs, framed_metas = preprocess([img_path], max_size=self.input_sizes[cfg.compound_coef])\n",
    "            x = torch.from_numpy(framed_imgs[0]).float()\n",
    "            x = x.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "            features, regression, classification, anchors = self.model(x)\n",
    "            preds = self._my_postprocess(x,\n",
    "                                anchors, regression, classification,\n",
    "                                regressBoxes, clipBoxes,\n",
    "                                0.7, 0.5)\n",
    "\n",
    "            preds = invert_affine(framed_metas, preds)[0]\n",
    "            scores = preds['scores']\n",
    "            class_ids = preds['class_ids']\n",
    "            rois = preds['rois']\n",
    "            image_result = {\n",
    "                'detection_classes': [],\n",
    "                'detection_boxes': [],\n",
    "                'detection_scores': []\n",
    "            }\n",
    "            if rois.shape[0] > 0:\n",
    "                bbox_score = scores\n",
    "                \n",
    "                for roi_id in range(rois.shape[0]):\n",
    "                    score = float(bbox_score[roi_id])\n",
    "                    label = int(class_ids[roi_id])\n",
    "                    box = rois[roi_id, :]\n",
    "                    image_result['detection_classes'].append(self.class_dict[label+1])\n",
    "                    image_result['detection_boxes'].append(box.tolist())\n",
    "                    image_result['detection_scores'].append(score)\n",
    "\n",
    "            results.append(image_result)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def postprocess(self, data):\n",
    "        if len(data) == 1:\n",
    "            return data[0]\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    def _my_postprocess(self, x, anchors, regression, classification, regressBoxes, clipBoxes, threshold, iou_threshold):\n",
    "        transformed_anchors = regressBoxes(anchors, regression)\n",
    "        transformed_anchors = clipBoxes(transformed_anchors, x)\n",
    "        scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
    "        scores_over_thresh = (scores > threshold)[:, :, 0]\n",
    "        out = []\n",
    "        for i in range(x.shape[0]):\n",
    "            if scores_over_thresh[i].sum() == 0:\n",
    "                out.append({\n",
    "                    'rois': np.array(()),\n",
    "                    'class_ids': np.array(()),\n",
    "                    'scores': np.array(()),\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            classification_per = classification[i, scores_over_thresh[i, :], ...].permute(1, 0)\n",
    "            transformed_anchors_per = transformed_anchors[i, scores_over_thresh[i, :], ...]\n",
    "            scores_per = scores[i, scores_over_thresh[i, :], ...]\n",
    "            scores_, classes_ = classification_per.max(dim=0)\n",
    "            anchors_nms_idx = batched_nms(transformed_anchors_per, scores_per[:, 0], classes_, iou_threshold=iou_threshold)\n",
    "\n",
    "            if anchors_nms_idx.shape[0] != 0:\n",
    "                classes_ = classes_[anchors_nms_idx]\n",
    "                scores_ = scores_[anchors_nms_idx]\n",
    "                boxes_ = transformed_anchors_per[anchors_nms_idx, :]\n",
    "                boxes_ = boxes_[:,[1,0,3,2]]\n",
    "\n",
    "                out.append({\n",
    "                    'rois': boxes_.numpy(),\n",
    "                    'class_ids': classes_.numpy(),\n",
    "                    'scores': scores_.numpy(),\n",
    "                })\n",
    "            else:\n",
    "                out.append({\n",
    "                    'rois': np.array(()),\n",
    "                    'class_ids': np.array(()),\n",
    "                    'scores': np.array(()),\n",
    "                })\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "service = PTVisionService(1, 'logs/auto/efficientdet-d1_27_7000.pth')\n",
    "data = service.preprocess({\"key\":{\"name1\":'data/labeled_data_backup/4785.jpg'}})\n",
    "data = service.inference(data)\n",
    "data = service.postprocess(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'detection_classes': ['speed_unlimited'],\n",
    " 'detection_boxes': [[423.39569091796875, 435.4236755371094, 459.3177490234375, 488.8864440917969]],\n",
    " 'detection_scores': [0.23959176242351532]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python lmw-pt",
   "language": "python",
   "name": "lmw-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
